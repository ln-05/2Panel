# Ollama模型管理系统

## 功能概述

这是一个基于Gin-Vue-Admin框架开发的Ollama模型管理系统，提供完整的AI模型私有化部署和对话功能。

## 主要功能

### 1. 模型管理
- **添加模型**: 从Ollama官方仓库下载模型
- **启动/停止模型**: 控制模型的运行状态
- **删除模型**: 删除不需要的模型
- **重建模型**: 重新下载和部署模型
- **同步模型**: 同步本地和远程模型状态

### 2. AI对话功能
- **实时对话**: 与运行中的模型进行实时对话
- **上下文保持**: 支持多轮对话的上下文记忆
- **模型切换**: 可以在不同模型间切换对话
- **对话历史**: 保存当前会话的对话记录

### 3. 系统监控
- **实时状态**: WebSocket实时更新模型状态
- **资源监控**: 监控系统资源使用情况
- **连接状态**: 显示与Ollama服务的连接状态

## 使用方法

### 访问系统
1. 启动后端服务
2. 启动前端服务
3. 访问 `http://localhost:8080/ollama-test` 进行功能测试
4. 访问 `http://localhost:8080/ollama` 进入主界面

### 添加模型
1. 点击"添加模型"按钮
2. 输入模型名称（如：llama2:7b）
3. 选择模型来源
4. 点击"开始下载"

### 启动模型
1. 在模型列表中找到已下载的模型
2. 点击"启动"按钮
3. 等待模型状态变为"运行中"

### 开始对话
1. 点击"AI对话"按钮或模型行的"对话"按钮
2. 选择要对话的模型（必须是运行中的模型）
3. 在输入框中输入问题
4. 按Ctrl+Enter或点击"发送"按钮

## 推荐模型

以下是一些推荐的模型：

- **llama2:7b** - 通用对话模型，平衡性能和资源消耗
- **codellama:7b** - 专门用于代码生成和编程问题
- **mistral:7b** - 高质量的对话模型
- **neural-chat:7b** - 优化的聊天模型
- **phi:2.7b** - 轻量级模型，资源消耗较少

## 系统要求

### 硬件要求
- **内存**: 至少8GB RAM（推荐16GB+）
- **存储**: 每个7B模型约需要4-5GB存储空间
- **CPU**: 多核处理器（推荐8核+）
- **GPU**: 可选，支持CUDA的GPU可加速推理

### 软件要求
- **Ollama服务**: 需要在服务器上运行Ollama服务
- **Docker**: 如果使用容器化部署
- **网络**: 稳定的网络连接用于下载模型

## 故障排除

### 常见问题

1. **模型下载失败**
   - 检查网络连接
   - 确认磁盘空间充足
   - 检查Ollama服务是否正常运行

2. **模型启动失败**
   - 检查系统内存是否充足
   - 确认模型文件完整性
   - 查看系统日志获取详细错误信息

3. **对话无响应**
   - 确认模型状态为"运行中"
   - 检查与后端API的连接
   - 查看浏览器控制台错误信息

4. **WebSocket连接失败**
   - 检查后端WebSocket服务是否启动
   - 确认防火墙设置
   - 刷新页面重新连接

### 调试模式
访问 `/ollama-test` 页面可以测试：
- API连接状态
- WebSocket连接状态
- 基本功能是否正常

## 技术架构

### 后端技术栈
- **Gin**: Web框架
- **GORM**: ORM框架
- **WebSocket**: 实时通信
- **Ollama API**: 模型管理和对话

### 前端技术栈
- **Vue 3**: 前端框架
- **Element Plus**: UI组件库
- **WebSocket**: 实时状态更新
- **Axios**: HTTP客户端

## 开发说明

### 目录结构
```
web/src/view/AI/ollamaModel/
├── index.vue                 # 主页面
├── test.vue                  # 测试页面
├── components/
│   ├── AddModelDialog.vue    # 添加模型对话框
│   └── ChatDialog.vue        # AI对话组件
├── composables/
│   └── useOllamaWebSocket.js # WebSocket管理
└── api/
    └── ollamaModel.js        # API接口
```

### API接口
- `GET /ollamaModel/search` - 搜索模型
- `POST /ollamaModel/create` - 创建模型
- `POST /ollamaModel/start` - 启动模型
- `POST /ollamaModel/stop` - 停止模型
- `POST /ollamaModel/chat` - 模型对话
- `POST /ollamaModel/sync` - 同步模型

## 更新日志

### v1.0.0 (当前版本)
- ✅ 基础模型管理功能
- ✅ AI对话功能
- ✅ WebSocket实时状态更新
- ✅ 系统资源监控
- ✅ 批量操作支持

### 计划功能
- 🔄 流式对话支持
- 🔄 对话历史持久化
- 🔄 模型性能监控
- 🔄 多用户会话管理