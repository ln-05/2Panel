# Ollama模型管理系统 - 快速启动指南

## 🚀 快速开始

### 前提条件
1. **Ollama服务已安装并运行**
   ```bash
   # 安装Ollama (如果未安装)
   curl -fsSL https://ollama.ai/install.sh | sh
   
   # 启动Ollama服务
   ollama serve
   ```

2. **后端服务运行**
   ```bash
   cd server
   go run main.go
   ```

3. **前端服务运行**
   ```bash
   cd web
   npm install
   npm run dev
   ```

### 🎯 5分钟快速体验

#### 步骤1: 访问测试页面
1. 打开浏览器访问: `http://localhost:8080/ollama-test`
2. 点击"测试API连接"确认后端连接正常
3. 点击"测试WebSocket连接"确认实时连接正常

#### 步骤2: 进入主界面
1. 点击"进入主页面"或直接访问: `http://localhost:8080/ollama`
2. 查看连接状态指示器（右上角）

#### 步骤3: 下载第一个模型
1. 点击"添加模型"按钮
2. 选择推荐模型 `phi:2.7b` (轻量级，下载快)
3. 点击"开始下载"
4. 等待下载完成（约1-2分钟）

#### 步骤4: 启动模型
1. 在模型列表中找到 `phi:2.7b`
2. 点击"启动"按钮
3. 等待状态变为"运行中"（约30秒）

#### 步骤5: 开始对话
1. 点击"AI对话"按钮
2. 确认已选择 `phi:2.7b` 模型
3. 输入问题: "你好，请介绍一下自己"
4. 按Ctrl+Enter或点击"发送"
5. 享受AI对话！

## 📋 推荐模型选择

### 🚀 快速体验 (资源有限)
- **phi:2.7b** - 1.5GB，启动快，适合测试
- **orca-mini:3b** - 2GB，轻量级，响应快

### 💪 平衡性能 (推荐)
- **llama2:7b** - 4GB，通用对话，性能均衡
- **mistral:7b** - 4GB，高质量对话
- **neural-chat:7b** - 4GB，优化聊天体验

### 🔥 高性能 (资源充足)
- **llama2:13b** - 7GB，更强大的理解能力
- **codellama:13b** - 7GB，专业代码生成

### 💻 代码专用
- **codellama:7b** - 4GB，代码生成和解释
- **starling-lm:7b** - 4GB，代码问答优化

## 🛠️ 常用操作

### 模型管理
```bash
# 查看已下载的模型
ollama list

# 手动下载模型
ollama pull llama2:7b

# 删除模型
ollama rm llama2:7b

# 运行模型 (命令行测试)
ollama run llama2:7b
```

### 系统监控
- **连接状态**: 查看右上角状态指示器
- **模型状态**: 查看模型列表中的状态列
- **资源使用**: 通过系统监控查看CPU/内存使用

### 对话技巧
1. **清晰提问**: 问题越具体，回答越准确
2. **上下文**: 系统会记住对话上下文
3. **模型切换**: 可以在不同模型间切换对话
4. **清空对话**: 点击"清空对话"重置上下文

## 🔧 故障排除

### 问题1: API连接失败
**症状**: 测试页面显示API连接失败
**解决**:
```bash
# 检查后端服务是否运行
curl http://localhost:8888/api/v1/ollamaModel/search

# 检查Ollama服务是否运行
curl http://localhost:11434/api/tags
```

### 问题2: WebSocket连接失败
**症状**: 连接状态显示"连接错误"
**解决**:
1. 刷新页面重新连接
2. 检查防火墙设置
3. 确认后端WebSocket服务正常

### 问题3: 模型下载失败
**症状**: 模型状态显示"错误"
**解决**:
1. 检查网络连接
2. 确认磁盘空间充足
3. 手动下载: `ollama pull 模型名称`

### 问题4: 模型启动失败
**症状**: 点击启动后状态仍为"已停止"
**解决**:
1. 检查系统内存是否充足
2. 确认模型文件完整性
3. 查看系统日志获取详细错误

### 问题5: 对话无响应
**症状**: 发送消息后没有回复
**解决**:
1. 确认模型状态为"运行中"
2. 检查浏览器控制台错误
3. 尝试重新启动模型

## 📊 性能建议

### 系统要求
- **最低配置**: 8GB RAM, 20GB 存储空间
- **推荐配置**: 16GB RAM, 50GB 存储空间
- **高性能配置**: 32GB RAM, 100GB 存储空间, GPU

### 模型选择建议
- **8GB RAM**: 选择3B-7B参数的模型
- **16GB RAM**: 可以运行7B-13B参数的模型
- **32GB+ RAM**: 可以运行更大的模型或多个模型

### 优化建议
1. **关闭不用的模型**: 节省内存资源
2. **定期清理**: 删除不需要的模型文件
3. **监控资源**: 注意CPU和内存使用情况
4. **网络优化**: 确保稳定的网络连接

## 🎯 使用场景

### 1. 日常对话助手
- 选择: `neural-chat:7b` 或 `mistral:7b`
- 用途: 日常问答、信息查询、创意写作

### 2. 编程助手
- 选择: `codellama:7b` 或 `codellama:13b`
- 用途: 代码生成、调试、代码解释

### 3. 学习助手
- 选择: `llama2:7b` 或 `llama2:13b`
- 用途: 知识问答、概念解释、学习指导

### 4. 轻量级应用
- 选择: `phi:2.7b` 或 `orca-mini:3b`
- 用途: 资源受限环境、快速响应场景

## 📞 获取帮助

如果遇到问题，可以：
1. 查看浏览器控制台错误信息
2. 检查后端服务日志
3. 访问测试页面进行诊断
4. 查看系统资源使用情况

---

**祝您使用愉快！🎉**